"""
Streamlit Webç•Œé¢
ä¸ºDeep Search Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src import DeepSearchAgent, Config


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="æœªæ¥ç®€äº‹",
        page_icon="ğŸ”®",
        layout="wide"
    )
    
    st.title("ğŸ”® æœªæ¥ç®€äº‹")
    st.markdown("**æ™ºèƒ½æœªæ¥è¶‹åŠ¿é¢„æµ‹ä¸åˆ†æå·¥å…·** - é€šè¿‡å¤šè½®æœç´¢å’Œåæ€ï¼Œå¸®ä½ äº†è§£æœªæ¥å¯èƒ½å‘ç”Ÿçš„äº‹æƒ…")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        # æœªæ¥ç®€äº‹é…ç½®
        st.subheader("ğŸ”® æœªæ¥ç®€äº‹è®¾ç½®")
        time_horizon = st.selectbox(
            "æ—¶é—´èŒƒå›´",
            ["1ä¸ªæœˆ", "3ä¸ªæœˆ", "6ä¸ªæœˆ", "1å¹´", "3å¹´", "5å¹´"],
            index=1,
            help="é€‰æ‹©è¦é¢„æµ‹çš„æœªæ¥æ—¶é—´èŒƒå›´"
        )
        
        analysis_angles = st.multiselect(
            "åˆ†æè§’åº¦ï¼ˆå¯é€‰ï¼‰",
            ["æŠ€æœ¯", "ç»æµ", "ç¤¾ä¼š", "ç¯å¢ƒ", "æ”¿æ²»", "æ–‡åŒ–", "å¥åº·", "æ•™è‚²"],
            default=["æŠ€æœ¯", "ç»æµ", "ç¤¾ä¼š"],
            help="é€‰æ‹©è¦ä»å“ªäº›è§’åº¦åˆ†ææœªæ¥è¶‹åŠ¿"
        )
        
        # APIå¯†é’¥é…ç½®
        st.subheader("ğŸ”‘ APIå¯†é’¥")
        deepseek_key = st.text_input("DeepSeek API Key", type="password", 
                                   value="")
        tavily_key = st.text_input("Tavily API Key", type="password",
                                 value="")
        
        # é«˜çº§é…ç½®
        st.subheader("âš™ï¸ é«˜çº§é…ç½®")
        max_reflections = st.slider("åæ€æ¬¡æ•°", 1, 5, 2)
        max_search_results = st.slider("æœç´¢ç»“æœæ•°", 1, 10, 3)
        max_content_length = st.number_input("æœ€å¤§å†…å®¹é•¿åº¦", 1000, 50000, 20000)
        
        # æ¨¡å‹é€‰æ‹©
        llm_provider = st.selectbox("LLMæä¾›å•†", ["deepseek", "openai"])
        
        if llm_provider == "deepseek":
            model_name = st.selectbox("DeepSeekæ¨¡å‹", ["deepseek-chat"])
        else:
            model_name = st.selectbox("OpenAIæ¨¡å‹", ["gpt-4o-mini", "gpt-4o"])
            openai_key = st.text_input("OpenAI API Key", type="password",
                                     value="")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ”® æœªæ¥é¢„æµ‹æŸ¥è¯¢")
        query = st.text_area(
            "è¯·è¾“å…¥æ‚¨æƒ³äº†è§£çš„æœªæ¥è¯é¢˜",
            placeholder="ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½çš„å‘å±•",
            height=100,
            help="è¾“å…¥æ‚¨æƒ³äº†è§£çš„æœªæ¥è¶‹åŠ¿æˆ–å¯èƒ½å‘ç”Ÿçš„äº‹ä»¶"
        )
        
        # é¢„è®¾æŸ¥è¯¢ç¤ºä¾‹
        st.subheader("ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢")
        example_queries = [
            "äººå·¥æ™ºèƒ½çš„å‘å±•",
            "ç”µåŠ¨æ±½è½¦å¸‚åœº",
            "è¿œç¨‹åŠå…¬è¶‹åŠ¿",
            "æ°”å€™å˜åŒ–å½±å“",
            "å¤ªç©ºæ¢ç´¢è¿›å±•",
            "ç”Ÿç‰©æŠ€æœ¯çªç ´",
            "æ•°å­—è´§å¸å‘å±•",
            "æ•™è‚²æ¨¡å¼å˜é©"
        ]
        
        selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹æŸ¥è¯¢", ["è‡ªå®šä¹‰"] + example_queries)
        if selected_example != "è‡ªå®šä¹‰":
            query = selected_example
    
    with col2:
        st.header("çŠ¶æ€ä¿¡æ¯")
        if 'agent' in st.session_state and hasattr(st.session_state.agent, 'state'):
            progress = st.session_state.agent.get_progress_summary()
            st.metric("æ€»æ®µè½æ•°", progress['total_paragraphs'])
            st.metric("å·²å®Œæˆ", progress['completed_paragraphs'])
            st.progress(progress['progress_percentage'] / 100)
        else:
            st.info("å°šæœªå¼€å§‹ç ”ç©¶")
    
    # æ‰§è¡ŒæŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        start_research = st.button("å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True)
    
    # éªŒè¯é…ç½®
    if start_research:
        if not query.strip():
            st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
            return
        
        if not deepseek_key and llm_provider == "deepseek":
            st.error("è¯·æä¾›DeepSeek API Key")
            return
        
        if not tavily_key:
            st.error("è¯·æä¾›Tavily API Key")
            return
        
        if llm_provider == "openai" and not openai_key:
            st.error("è¯·æä¾›OpenAI API Key")
            return
        
        # åˆ›å»ºé…ç½®
        config = Config(
            deepseek_api_key=deepseek_key if llm_provider == "deepseek" else None,
            openai_api_key=openai_key if llm_provider == "openai" else None,
            tavily_api_key=tavily_key,
            default_llm_provider=llm_provider,
            deepseek_model=model_name if llm_provider == "deepseek" else "deepseek-chat",
            openai_model=model_name if llm_provider == "openai" else "gpt-4o-mini",
            max_reflections=max_reflections,
            max_search_results=max_search_results,
            max_content_length=max_content_length,
            output_dir="streamlit_reports",
            time_horizon=time_horizon,
            analysis_angles=analysis_angles if analysis_angles else None
        )
        
        # æ‰§è¡Œç ”ç©¶
        execute_research(query, config)


def execute_research(query: str, config: Config):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        agent = DeepSearchAgent(config)
        st.session_state.agent = agent
        
        progress_bar.progress(10)
        
        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æ„...")
        agent._generate_report_structure(query)
        progress_bar.progress(20)
        
        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i+1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")
            
            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))
            
            # åæ€å¾ªç¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()
            
            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)
        
        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)
        
        status_text.text("ç ”ç©¶å®Œæˆï¼")
        
        # æ˜¾ç¤ºç»“æœ
        display_results(agent, final_report)
        
    except Exception as e:
        st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
    st.header("ğŸ“Š é¢„æµ‹ç»“æœ")
    
    # ç»“æœæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ å®Œæ•´æŠ¥å‘Š", "ğŸ” è¯¦ç»†ä¿¡æ¯", "ğŸ’¾ ä¸‹è½½"])
    
    with tab1:
        st.markdown(final_report)
    
    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i+1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..." 
                        if len(paragraph.research.latest_summary) > 300 
                        else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)
        
        # æœç´¢å†å²
        st.subheader("æœç´¢å†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)
        
        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i+1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**", search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)
    
    with tab3:
        # ä¸‹è½½é€‰é¡¹
        st.subheader("ä¸‹è½½æŠ¥å‘Š")
        
        # Markdownä¸‹è½½
        st.download_button(
            label="ä¸‹è½½MarkdownæŠ¥å‘Š",
            data=final_report,
            file_name=f"deep_search_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
        
        # JSONçŠ¶æ€ä¸‹è½½
        state_json = agent.state.to_json()
        st.download_button(
            label="ä¸‹è½½çŠ¶æ€æ–‡ä»¶",
            data=state_json,
            file_name=f"deep_search_state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )


if __name__ == "__main__":
    main()
